import csv
import numpy as np
from operator import attrgetter
import os

from spta.region import Point
from .factory import ClusteringFactory, ClusteringMetadataFactory

from spta.region.partition import intra_cluster_cost
from spta.util import log as log_util


class ClusteringSuite(log_util.LoggerMixin):
    '''
    Abstraction that deals with a set of clustering algorithms, generated by combinations of their
    parameters. Example: for k-medoids, use a range of ks and seeds to create a list of
    KmedoidsClusteringMetadata instances with default k-medoids parameters.
    '''

    def __init__(self, identifier, metadata_name, **parameter_combinations):
        '''
        Create an instance of ClusteringSuite.

        identifier
            A suite has an identifier created by the user

        metadata_name
            Represents which clustering algorithm to use (e.g. 'kmedoids'). The metadata_name must
            match one of the available ClusteringMetadata subtypes available, a suite cannot
            include multiple metadata subtypes.

        parameter_combinations
            A dictionary, where each key represents a parameter of a ClusteringMetadata.
            The value of each key can either be single-valued or a list. If it is an iterable,
            then  this indicates that mulitple metadata instances are desired. The parameters
            are combined using cartesian product of their values.
            Note: cannot support initial_medoids argument of k-medoids, since it is a list.
            Note: for now, only k and random_seed can be iterated, this simplifies code.

        Example of k-medoids suite:

        identifier: quick
        metadata_name: kmedoids
        parameter_combinations: {
            k: {2, 3},
            random_seed: {0, 1},
            mode: 'lite'
        }

        This will create the following suite with default values of the optional parameters:
        kmedoids_k2_seed0_lite
        kmedoids_k2_seed1_lite
        kmedoids_k3_seed0_lite
        kmedoids_k3_seed1_lite
        '''
        self.logger.debug('Creating clustering suite: {} - {}'.format(identifier, metadata_name))
        self.identifier = identifier
        self.metadata_name = metadata_name

        # used to build instances
        self.factory = ClusteringMetadataFactory()

        # create the ClusteringMetadata instances
        # TODO all suites are created inside experiments.metadata, maybe lazy instantiation here?
        self.metadatas = self.__create_metadata_instances(**parameter_combinations)

    def __create_metadata_instances(self, **parameter_combinations):
        '''
        Creates the list of metadata instances given suite parameters, called during construction.
        Uses the ClusteringMetadataFactory to achieve this.
        '''

        # required
        ks = parameter_combinations.pop('k')

        # optional
        random_seeds = (1,)   # ugly but need to iterate in regular...
        if 'random_seed' in parameter_combinations:

            # received random seed parameter, is it a list or a single value?
            random_seeds = parameter_combinations.pop('random_seed')
            if isinstance(random_seeds, int):
                # single value, convert to list
                random_seeds = (random_seeds,)

        # assume the remaining paratemeters are not to be iterated in the suite
        single_value_parameters = dict(parameter_combinations)

        instances = []
        for k in ks:
            for random_seed in random_seeds:

                # put each seed here
                single_value_parameters['random_seed'] = random_seed

                # create each instance
                instances.append(self.factory.instance(self.metadata_name, k,
                                                       **single_value_parameters))

        return instances

    def retrieve_suite_result_csv(self, output_home, region_metadata, distance_measure):
        '''
        This will open the result CSV of analizing the current clustering suite, e.g.
        outputs/nordeste_small_2015_2015_1spd/dtw/clustering__kmedoids-quick.csv

        Then it reads, for each tuple, the metadata representation and the list of medoids.
        Returns a dictionary, where each key is a metadata representation and the value is the
        corresponding list of medoids. Given the metadata representation string, the metadata
        instance can be retrieved using ClusteringMetadataFactory.from_repr()

        {
            'kmedoids_k2_seed0_lite': [Point(45,86), Point(47,91)],
            'kmedoids_k3_seed0_lite': [Point(45,86), Point(48,89), Point(45,92)],
            ...
        }
        '''
        result = {}

        # the suite knows where its result should be stored
        analysis_csv_filepath = \
            self.analysis_csv_filepath(output_home, region_metadata, distance_measure)

        if not os.path.isfile(analysis_csv_filepath):
            raise ValueError('Could not find CSV: {}'.format(analysis_csv_filepath))

        # open the CSV, ignore header
        with open(analysis_csv_filepath, newline='') as csvfile:
            csv_reader = csv.reader(csvfile, delimiter=' ', quotechar='|',
                                    quoting=csv.QUOTE_MINIMAL)
            # ignore header
            next(csv_reader)

            for row in csv_reader:
                # the first column is the representation of the clustering, this is used as key
                clustering_repr = row[0]

                # the second column is the total result, don't want this
                # the third column is the list of medoids as string, use this to create the point
                # instances representing the medoids of the clustering
                medoids_str = row[2]

                # string manipulations to retrieve the medoids as Point instances
                medoids_str_elems = medoids_str.split(' ')[:-1]
                medoids_str_coord_pairs = [
                    medoids_str_elem[1:-1].split(',')
                    for medoids_str_elem
                    in medoids_str_elems
                ]
                medoids = [
                    Point(int(medoids_str_coord_pair[0]), int(medoids_str_coord_pair[1]))
                    for medoids_str_coord_pair
                    in medoids_str_coord_pairs
                ]

                # store this tuple
                result[clustering_repr] = medoids

        return result

    def csv_dir(self, output_home, region_metadata, distance_measure):
        '''
        Directory of the output CSV when analyzing this suite.
        Example: outputs/nordeste_small_2015_2015_1spd/dtw
        '''
        region_output_dir = region_metadata.output_dir(output_home)
        return '{}/{!r}'.format(region_output_dir, distance_measure)

    def csv_suite_dir(self, output_home, region_metadata, distance_measure):
        '''
        Directory of CSV files for solvers using this suite (e.g. classifier)
        '''
        csv_dir = self.csv_dir(output_home, region_metadata, distance_measure)
        subdir = '{!r}'.format(self)
        return os.path.join(csv_dir, subdir)

    def analysis_csv_filename(self):
        '''
        Name of output CSV when analyzing this suite.
        Example: clustering__kmedoids-quick.csv
        '''
        return 'clustering__{!r}.csv'.format(self)

    def analysis_csv_filepath(self, output_home, region_metadata, distance_measure):
        '''
        Full path of the output CSV when analyzing this suite.
        Example: outputs/nordeste_small_2015_2015_1spd/dtw/clustering__kmedoids-quick.csv
        '''
        csv_dir = self.csv_dir(output_home, region_metadata, distance_measure)
        return '{}/{}'.format(csv_dir, self.analysis_csv_filename())

    def medoid_series_csv_filename(self):
        '''
        Returns the CSV filename for the list of medoids that appear in a clustering suite.
        The CSV will describe the clustering metadata, the medoid index and the time series
        that corresponds to a given spatio-temporal region.
        '''
        return 'medoid_data__{!r}.csv'.format(self)

    def medoid_series_csv_filepath(self, output_home, region_metadata, distance_measure):
        csv_dir = self.csv_dir(output_home, region_metadata, distance_measure)
        return '{}/{}'.format(csv_dir, self.medoid_series_csv_filename())

    def classifier_csv_filename(self, prediction_region, tp):
        '''
        Given a classifier that was trained with the information provided by min_distance,
        and given its output for classifying the points in a prediction region with a value of
        tp for number of past samples, return the CSV filename.

        Example:
        clustering__classifier_result__kmedoids-quick__region-0-5-0-5__tp8.csv
        '''
        # TODO make region calculate its own string
        region_str = 'region-0-5-0-5'
        tp_str = 'tp8'
        return 'clustering__classifier_result__{!r}__{}__{}.csv'.format(self, region_str, tp_str)

    def __iter__(self):
        '''
        Used for iterating over metadata instances.
        '''
        return iter(self.metadatas)

    def __repr__(self):
        return '{}-{}'.format(self.metadata_name, self.identifier)


class OrganizeClusteringSuite(log_util.LoggerMixin):
    '''
    Given a clustering suite, organizes it in some meaningful way.
    For kmedoids clustering algorithms, the suite is separated into random seesds, and ordered by k.
    '''

    def organize_kmedoids_suite(self, kmedoids_clustering_suite):
        '''
        Returns a dictionary where the keys are the random seeds available in the suite, and the values
        are lists of clustering metadata instances. For each seed, the list will contain instances for
        that seed and will be ordered in values increasing by k.
        '''

        metadatas_by_seed = {}

        # add metadata to correct keys
        for kmedoids_metadata in kmedoids_clustering_suite:

            random_seed = kmedoids_metadata.random_seed
            if random_seed not in metadatas_by_seed:
                metadatas_by_seed[random_seed] = []

            metadatas_by_seed[random_seed].append(kmedoids_metadata)

        # order each key
        ordered_metadatas_by_seed = {}
        for random_seed, metadatas_for_seed in metadatas_by_seed.items():
            ordered_metadatas_by_seed[random_seed] = sorted(metadatas_for_seed, key=attrgetter('k'))
            self.logger.debug('Metadatas for seed {} -> {}'.format(random_seed, ordered_metadatas_by_seed[random_seed]))

        return ordered_metadatas_by_seed


class FindSuiteElbow(log_util.LoggerMixin):
    '''
    Given a clustering suite, find the a single value of 'k' that represents the 'elbow' of the
    intra-cluster distances.
    '''

    def __init__(self, clustering_suite, spt_region, distance_measure):
        self.clustering_suite = clustering_suite
        self.spt_region = spt_region
        self.distance_measure = distance_measure
        self.clustering_factory = ClusteringFactory(distance_measure)

    def calculate_elbows_kmedoids(self, pickle_home):
        '''
        Use the methods below to find the elbows for the current suite.
        There will be as many elbows as there are seeds in the suite: to find the elbow,
        we assume that the cost is a function of k alone, and find the point with the largest
        value of the estimated second derivative of the cost.
        This assumes different values for k, so we separate by seed using OrganizeClusteringSuite.

        Uses the other methods of this class!

        Returns a dictionary (seed, elbow_metadata) is a kmedoids clustering metadata where the elbow happens
        for that seed.
        '''
        partitions_by_metadata = self.get_all_partitions(pickle_home)
        self.logger.debug('Metadatas in suite: {}'.format(partitions_by_metadata.keys()))

        costs_by_metadata = self.get_all_intra_cluster_costs(partitions_by_metadata)
        elbows_by_seed = self.find_cost_elbow_for_each_kmedoids_seed(costs_by_metadata)
        return elbows_by_seed

    def get_all_partitions(self, pickle_home):
        '''
        For each clustering algorithm in the suite, find its corresponding partition.
        If the partition was saved, this should recover the partition to avoid recomputing the clustering.
        Returns a dictionary where the keys are clustering_metadata instances and the values are the
        corresponding partitions.
        '''

        partitions_by_metadata = {}

        for clustering_metadata in self.clustering_suite:

            # ask the clustering algorithm for its partition,
            # will either calculate it or retrieved a saved one
            clustering_algorithm = self.clustering_factory.instance(clustering_metadata)
            partition = clustering_algorithm.partition(spt_region=self.spt_region,
                                                       with_medoids=True,
                                                       pickle_home=pickle_home)
            partitions_by_metadata[clustering_metadata] = partition

        return partitions_by_metadata

    def get_all_intra_cluster_costs(self, partitions_by_metadata):
        '''
        Ask each partition to calculate its total intra cluster cost.
        '''
        costs_by_metadata = {}

        for (clustering_metadata, partition) in partitions_by_metadata.items():
            this_intra_cluster_cost = intra_cluster_cost(partition, self.spt_region, self.distance_measure)
            costs_by_metadata[clustering_metadata] = this_intra_cluster_cost
            self.logger.debug('Cost: {} -> {:.2f}'.format(clustering_metadata, this_intra_cluster_cost))

        return costs_by_metadata

    def find_cost_elbow_given_order(self, costs_by_metadata, ordered_metadata_instances):
        '''
        Given a particular order of metadata instances and the intra cluster cost of each metadata,
        calculate the 'elbow' metadata, identified by the maximum value of an approximate second derivative
        of the intra cluster cost, when ordered by order given by ordered_metadata_instances.

        This implementation takes into account the possibility of uneven spacing of the values of k
        Using this implementation of a discrete second derivative:
        https://mathformeremortals.wordpress.com/2013/01/12/a-numerical-second-derivative-from-three-points

        NOTE: for this to make sense with k-medoids, the data should only be about a single random_seed, and the
        order should be by increasing values of k. See method below.
        NOTE: if the value of k is repeated once, then the equation breaks!
        '''
        # sanity checks: same length, at least three points
        assert len(costs_by_metadata.keys()) == len(ordered_metadata_instances)
        assert len(costs_by_metadata.keys()) >= 3

        # x in the formula
        ordered_k = [metadata.k for metadata in ordered_metadata_instances]

        # y in the formula
        ordered_costs = [costs_by_metadata[metadata] for metadata in ordered_metadata_instances]

        highest_second_derivative = -np.Inf
        index_with_highest_second_derivative = -1

        # iterate so that we have one value before and one value after
        for i in range(1, len(ordered_k) - 1):
            (x1, x2, x3) = ordered_k[i - 1:i + 2]
            (y1, y2, y3) = ordered_costs[i - 1:i + 2]

            # apply the second derivative
            coef_y1 = 2.0 / ((x2 - x1) * (x3 - x1))
            coef_y2 = -2.0 / ((x3 - x2) * (x2 - x1))
            coef_y3 = 2.0 / ((x3 - x2) * (x3 - x1))

            second_derivative = coef_y1 * y1 + coef_y2 * y2 + coef_y3 * y3

            msg = 'd^2/dk^2 (k={}) -> {}'.format(x2, second_derivative)
            print(msg)
            self.logger.debug(msg)

            if second_derivative > highest_second_derivative:
                highest_second_derivative = second_derivative
                index_with_highest_second_derivative = i

        # return metadata with highest second derivative
        return ordered_metadata_instances[index_with_highest_second_derivative]

    def find_cost_elbow_for_each_kmedoids_seed(self, costs_by_metadata):
        '''
        Uses OrganizeClusteringSuite to organize the metadata instances in the clustering suite.
        Uses find_cost_elbow_given_order method
        Assumes k-medoids!
        '''
        organizer = OrganizeClusteringSuite()
        ordered_metadatas_by_seed = organizer.organize_kmedoids_suite(self.clustering_suite)

        # each seed has its own elbow
        elbows_by_seed = {}

        for (seed, ordered_metadata_instances) in ordered_metadatas_by_seed.items():

            # need the corresponding costs for the current metadatas
            costs_by_metadata_for_this_seed = {}
            for metadata in ordered_metadata_instances:
                costs_by_metadata_for_this_seed[metadata] = costs_by_metadata[metadata]

            elbow_for_this_seed = self.find_cost_elbow_given_order(costs_by_metadata, ordered_metadata_instances)
            elbows_by_seed[seed] = elbow_for_this_seed

        return elbows_by_seed
